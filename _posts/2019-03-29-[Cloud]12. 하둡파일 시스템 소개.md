---
layout: post
title: "[Cloud]12. 하둡파일 시스템 소개"
description: 
image: '../images/강아지57.jpg'
category: 'Cloud'
tags : 
- IT
- Cloud

twitter_text: 
introduction : 하둡파일 시스템 소개
---


### [1. 하둡 소개]

**하둡 소개**
- 하둡이란? 
	- 분산 컴퓨팅을 지원하는 프레임워크
	- 컴퓨터의 클러스트를 위해 존재
	- 많은 수의 노드를 붙일 수 있음
	- petabytes 데이터 지원
	- 오픈소스
	- 아파치 그룹 프로젝트
- 하둡이 왜 필요했나?
	- 어플리케이션 scale up 필요
	- 여러 컴퓨터를 붙여서 데이터 처리 속도 문제를 해결했으나 신뢰성 문제 발생(컴퓨터 fail, 클러스터 크기가 고정되지 않아 관리가 잘 되지 않음)
	- 효율적이고 신뢰성있는 인프라 필요성 대두
- 해결책
	- 많은 데이터와 많은 노드들에서 발생하는 신뢰성문제를 해결하기 위해 아파치에서 오픈소스 프로젝트 진행
	- 하둡 코어
		- 분산파일시스템 : 분산 데이터
		- map/reduce : 분산 어플리케이션
	- 자바로 구현
	- Linux, Mac, Windows, Solaris에서 구동되며 Commodity hardware(범용 하드웨어)에서 동작함
- Hive?
	- 여러개의 하둡 프로젝트 중 한개
	- 데이터가 많고 데이터 추상화가 어렵고 테이블,스키마, 파티션 등을 효율적으로 관리할 필요가 생김. 정형화 되지 않은 데이터 포멧을 처리할 필요가 생김
- 하둡 사용자 : Amazon/A9, Facebook, Google, IBM, Joost, Last.fm, New York Times, PowerSEt, Veoh, Yahoo



_ _ _

### [HDFS]

**HDFS**
- 범용 하드웨어에서 활용
	- 2 level 아키텍쳐
	- 노드들은 범용 pc
	- 한 rack에 30-40노드 존재
	- 네트워크는 backbone 으로 나가기 위해 3-4기가 LAN카드
	- switch 에 붙기 위해 1기가 LAN카드
- HDFS 목표
	- 매우 큰 분산 파일 시스템(big data 수용을 위한 파일 시스템) : 10K nodes, 1억개의 파일, 10PB 지원
	- 범용 하드웨어 활용
		- 하드웨어 failure 대비한 파일 중복
		- failure 감시 및 recover 지원
	- 배치 프로세싱 최적화
		- 데이터 위치가 들어나면 Computation이 데이터가 존재하는 곳으로 이동해서 처리(Data Centric Computing) - 네트워크 delay를 줄임
		- 커널이 아닌 어플리케이션 level에서 수행됨. 다양한 OS의 지원받음
- 분산파일시스템
	- 하나의 namespace 공간을 가짐
	- 데이터 일치성을 위해 
		- 동시에 한번 write, read는 여러번 가능
		- 클라이언트는 현재 파일에 덧붙일 수만 있음
	- 파일은 block으로 나눠짐
		- 128MB block으로 1개의 노드에 저장됨
		- 각각의 block은 중복되게 다른 여러 데이터노드/rack에 저장
	- Intelligent Client
		- 클라이언트는 block의 위치를 찾을 수 있어야 한다
		- 클라이언트는 데이터 노드로부터 직접 데이터에 접근해야 한다
- Block 배치
	- 기본적으로 3개의 replica(복제품) 존재하지만 수정 가능함
	- Block의 배치
		- 같은 노드
		- 다른 rack
		- 또 다른 rack
	- 클라이언트는 접근성이 좋은 replica(복제품)를 읽는다
	- 복제가 실패하면 시스템이 자동적으로 재 복제한다
- Data Correctness(데이터 정확성)
	- 데이터는 CRC32로 체크된다(네트워크)
	- 파일 생성
		- 521byte checksum으로 계산
		- 데이터가 DataNode에 저장될 때 파일 밑에 checksum도 저장됨
	- 파일 접근
		- 클라이언트는 DataNode의 파일과 checksum을 읽을 수 있음
		- 파일 확인을 실패하면 다른 복제품에 접근
	- Periodic Validation(주기적으로 시스템 확인)
- NameNode Metadata
	- Meta-data in Memory
		- 전체 meta-data가 메인 메모리에 올라감
		- 페이징 필요없음
	- Type of Metadata
		- 파일 리스트
		- 각 파일의 block 리스트
		- 각 블락의 DataNode 리스트
		- 파일속성(생성시간, 파일형식, 복제정보 등)
	- Transaction Log
		- 파일 생성, 파일 삭제 등을 기록
- DataNode
	- A Block Server
		- 로컬 파일 시스템에 데이터 저장
		- 각 블락의 메타데이터도 저장
		- 데이터와 메타데이터를 클라이언트에게 제공
	- Block Report
		- 주기적으로 NameNode에게 존재하는 모든 block정보를 전송한다
	- Facilitates pipelining data
		- 저장되지 못한 데이터는 또다른 DataNode에 하나씩 저장된다
- NameNode Failure
	- 트랜잭션 로그는 여러 디렉토리에 저장된다
	- NameNode의 HA(High Availability)를 지원해주는 솔루션이 중요하다
- Data Pipelining
	- 클라이언트가 첫번째 DataNode에 block을 write하면 첫번째 DataNode는 데이터를 파이프라인을 통해서 next DataNode로 보낸다
	- 모든 복제가 잘성되면 클라이언트는 파일의 다음 block으로 이동한다
- Rebalancer
	- 데이터 노드들의 balance를 맞춰줌
		- 새로운 노드가 추가되었을 때 동작
		- 클러스터가 온라인이고 rebalancer가 active일때
		- rebalancer는 network 혼잡이 발생하지 않도록 도와줌
		- command line tool 제공
- Hadoop 은 파일시스템을 지원한다
	- HDFS : Hadoop's own file system
	- Amazon S3 file system
	- CloudStore
	- FTP Filesystem
	- Read-only Http and Https file systems
- Rack Awareness
	- 서버 클러스터링 위치에 따라 최적화
	- 서버간 네트워크 트래픽이 클러스트 위치에 따라 최소화 될 수 있음
- HDFS : Hadoop Distr File System 
	- petabyte 스토리지, 파일시스템 위에서 운영됨
	- Master("NameNode")가 복제, 삭제, 생성 등을 관리한다
	- Slave("DataNode")는 데이터 검색을 관리한다
	- 파일은 여러 block에 저장되며 blcok id가 생성됨
- Application Programming Interface
	- HDFS는 사용하는 어플리케이션을 위해 Java API를 제공
	- Python 접근도 사용된다
	- C언어도 Wrapper를 이용하면 가능하다
- Map and Reduce
	- Functional Programming Languages

_ _ _


*출처 : 
- **클라우드 컴퓨팅 핵심기술 요소의 이해** 사내교육 참고