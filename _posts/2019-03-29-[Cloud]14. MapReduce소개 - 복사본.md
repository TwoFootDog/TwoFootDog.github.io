---
layout: post
title: "[Cloud]14. Map/Reduce 소개"
description: 
image: '../images/강아지58.jpg'
category: 'Cloud'
tags : 
- IT
- Cloud

twitter_text: 
introduction : Map/Reduce 소개
---


### [1. MapReduce overview]

**MapReduce overview**
- MapReduce
	- 범용 PC의 클러스터를 사용하여 고성능을 내게 해주고 자동적으로 병렬화 시켜주고 큰 스케일의 계산을 분산시켜주는 간단하고 강력한 인터페이스
- Before MapReduce
	- 큰 데이터 처리는 어려웠음
		- 몇백 or 몇천개의 프로세서 관리
		- 병렬 or 분산 관리
		- I/O 스케쥴링
		- 상태 모니터링
		- Fault/crash 허용
	- MapReduce는 위에 모든것을 쉽게 제공한다
- 구글에서 개발되고 사용된 프로그래밍 모델
- Map과 Reduce 모델의 결합
- 큰 데이터를 처리하거나 생성하는데 사용됨
- 확장이 쉽고 신뢰성있는 프로그래밍 모델


**Commodity Clusters**
- 웹 데이터 셋은 매우 클 수 있다
- 한개의 서버로는 처리가 불가능하다
- 처리를 하기 위해서는 범용pc 리눅스 노드 클러스터가 필요하다
- 상호 연결이 gigabit 이더넷 네트워크로 구축되어야 한다
- 하드웨어가 오류가 났을 때 감추는 기술이 필요하다


**안정적인 스토리지**
- 하나의 노드가 실패하면 데이터를 안전하게 저장할 수 있을까?
- 답 : 분산파일 시스템(구글 GFS, 하둡 HDFS, kosmix KFS)
- 대표적인 사용 패턴
	- rjeogks vkdlf(100기가에서 테라바이트)
	- 데이터는 업데이트는 자주 일어나지 않고 읽거나 append가 일어난다


**분산파일시스템**
- Chunk Servers
	- 파일이 chunk로 나눠진다
	- 일반적으로 각 chunk는 16-64MB이다
	- 각각의 chunk는 복제된다(보통 2X or 3X)
	- 다른 Rack에 복제된다
- Master node
	- HDFS의 Name Nodes라고 불린다
	- 메타데이터를 저장하고 복제한다
- 파일 접근을 위한 Client Library
	- chunk 서버를 찾기 위해 master에게 talk
	- 데이터 접근을 위해 chunk 서버에 직접 연결

_ _ _


### [2. MapReduce Flow]

**MapReduce Dataflow**
- InputData -> Map Function -> Reduce Function-> OutputData
- Map Function 수는 MasterNode의 Job Tracker에 의해 결정됨. Job Tracker는 SlaveNode의 Task Tracker에게 Job 수행을 명령한다
- SlaveNode는 Input Data로부터 데이터를 읽어와서 수행 후 결과를 파일시스템의 정해진 위치에 넣어준다(MasterNode에게 저장 위치 확인)
- Reduce는 MasterNode로부터 저장된 위치 확인 후 데이터 읽어서 처리


**Map & Reduce abstraction**
- Map Abstraction
	- Input a Key/value pair
		- key는 input value의 reference
		- value는 data set
	- Evaluation
		- 유저에 의해 구현된 function
		- 입력된 모든 value에 적용 가능
	- Produces a new list of key/value pairs
- Reduce Abstraction
	- Typically a function that :
		- 여러개의 key/pairs로 시작
			- 모든 파일에서 찾아진 각 단어의 하나의 key/value에서 같은 단어를 찾음
		- 적은 수의 key/value paire로 끝남
			- key/value가 같을 경우 sum
		- 작업이 다 끝나면 값을 돌려줌
- 어떻게 Map과 Reduce는 함께 일할까
	- Map이 정보를 전달
	- Reduce가 정보를 받음
	- 유저가 만든 function에 따라서 정보 처리
- MapReduce 처리 상세
	- 입력값에서 값이 없을 수도 있고, Map에 의한 처리 결과가 없을수도 있음
	- 분산환경에서의 성능향상을 위해서는 input partitions도 중요하다
- MapReduce 장점
	- 병렬 프로그래밍 복잡성을 줄여줌
		- Synchronization 복잡성을 줄여줌
		- 자동으로 data partitions
		- failure transparency 제공
		- 로드밸런싱 관리
	- 매일 1000개의 Google MapReduce job이 수행되고 있다



_ _ _


### [3. MapReduce example]

**MapReduce Examples**
- Distributed grep
- URL access frequency

**A Brief History**
- Functional Programming(Lisp)
	- map function : 각각의 value에 function 적용
	- reduce function : 결과를 합침

**MapReduce Execution Overview**
- Fault Tolerance
	- Master process periodically pings workers
		- Map-task failure : 재실행(모든 결과는 로컬에 저장)
		- reduce-task failure : 실패된 부분만 재실행(모든 결과는 global file system에 저장)

**다른 applications**
- Yahoo : Webmap application(웹페이지)
- Facebook : Hive data center(통계, 광고 등)
- Rackspace : 로그파일 분석

_ _ _


*출처 : 
- **클라우드 컴퓨팅 핵심기술 요소의 이해** 사내교육 참고